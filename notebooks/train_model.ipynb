{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Plant Disease Detection Training\n",
                "This notebook trains an EfficientNetV2-S model on the PlantVillage dataset using PyTorch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import datasets, transforms, models\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(\"Device:\", device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset Discovery\n",
                "Automatically locate the dataset and train/validation directories."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find dataset\n",
                "base_input = \"/kaggle/input\"\n",
                "dataset_path = None\n",
                "for folder in os.listdir(base_input):\n",
                "    if any(x in folder.lower() for x in [\"plant\", \"disease\", \"village\"]):\n",
                "        dataset_path = os.path.join(base_input, folder)\n",
                "        break\n",
                "\n",
                "if dataset_path is None:\n",
                "    raise Exception(\"Dataset not found\")\n",
                "\n",
                "print(\"Dataset:\", dataset_path)\n",
                "\n",
                "# find train / val dirs\n",
                "train_dir, val_dir = None, None\n",
                "for root, dirs, _ in os.walk(dataset_path):\n",
                "    low = [d.lower() for d in dirs]\n",
                "    if \"train\" in low and (\"valid\" in low or \"val\" in low):\n",
                "        train_dir = os.path.join(root, dirs[low.index(\"train\")])\n",
                "        val_dir = os.path.join(root, dirs[low.index(\"valid\")] if \"valid\" in low else os.path.join(root, dirs[low.index(\"val\")]))\n",
                "        break\n",
                "\n",
                "if train_dir is None or val_dir is None:\n",
                "    raise Exception(\"Train/Val folders missing\")\n",
                "\n",
                "print(\"Train:\", train_dir)\n",
                "print(\"Val:\", val_dir)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading\n",
                "Set up transforms and data loaders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# data\n",
                "IMAGE_SIZE = 160\n",
                "BATCH = 32\n",
                "EPOCHS = 15\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
                "    transforms.ToTensor()\n",
                "])\n",
                "\n",
                "train_ds = datasets.ImageFolder(train_dir, transform=transform)\n",
                "val_ds = datasets.ImageFolder(val_dir, transform=transform)\n",
                "\n",
                "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n",
                "\n",
                "class_names = train_ds.classes\n",
                "print(\"Classes:\", len(class_names))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Setup\n",
                "Initialize EfficientNetV2-S and modify the classifier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model\n",
                "model = models.efficientnet_v2_s(weights=None)\n",
                "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))\n",
                "model = model.to(device)\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
                "scaler = torch.amp.GradScaler(device=\"cuda\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Loop\n",
                "Train the model with mixed precision."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train\n",
                "train_acc_list, val_acc_list = [], []\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    correct, total = 0, 0\n",
                "\n",
                "    for imgs, labels in train_loader:\n",
                "        imgs, labels = imgs.to(device), labels.to(device)\n",
                "        optimizer.zero_grad()\n",
                "\n",
                "        with torch.amp.autocast(device_type=\"cuda\"):\n",
                "            outputs = model(imgs)\n",
                "            loss = criterion(outputs, labels)\n",
                "\n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += labels.size(0)\n",
                "        correct += predicted.eq(labels).sum().item()\n",
                "\n",
                "    train_acc = 100 * correct / total\n",
                "    train_acc_list.append(train_acc)\n",
                "\n",
                "    # validate\n",
                "    model.eval()\n",
                "    correct, total = 0, 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for imgs, labels in val_loader:\n",
                "            imgs, labels = imgs.to(device), labels.to(device)\n",
                "            outputs = model(imgs)\n",
                "            _, predicted = outputs.max(1)\n",
                "            total += labels.size(0)\n",
                "            correct += predicted.eq(labels).sum().item()\n",
                "\n",
                "    val_acc = 100 * correct / total\n",
                "    val_acc_list.append(val_acc)\n",
                "\n",
                "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train: {train_acc:.2f}% | Val: {val_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save & Plot\n",
                "Save the trained model and plot accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save\n",
                "torch.save(model.state_dict(), \"plant_disease_model.pth\")\n",
                "print(\"Saved: plant_disease_model.pth\")\n",
                "\n",
                "# plot\n",
                "plt.plot(train_acc_list, label=\"Train Acc\")\n",
                "plt.plot(val_acc_list, label=\"Val Acc\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}